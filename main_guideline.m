% Simple Random Forest Toolbox for Matlab
% written by Mang Shao and Tae-Kyun Kim, June 20, 2014.
% updated by Tae-Kyun Kim, Feb 09, 2017

% This is a guideline script of simple-RF toolbox.
% The codes are made for educational purposes only.
% Some parts are inspired by Karpathy's RF Toolbox

% Under BSD Licence

% Initialisation
init;

% Select dataset
[data_train, data_test] = getData('Toy_Spiral'); % {'Toy_Gaussian', 'Toy_Spiral', 'Toy_Circle', 'Caltech'}

%%
%%%%%%%%%%%%%
% check the training and testing data
    % data_train(:,1:2) : [num_data x dim] Training 2D vectors
    % data_train(:,3) : [num_data x 1] Labels of training data, {1,2,3}
    
plot_toydata(data_train);

    % data_test(:,1:2) : [num_data x dim] Testing 2D vectors, 2D points in the
    % uniform dense grid within the range of [-1.5, 1.5]
    % data_train(:,3) : N/A
    
scatter(data_test(:,1),data_test(:,2),'.b');


%% Visualize some bootstrapped bags
% Bootstraping aggregating
[N,D] = size(data_train);
frac = 1 - 1/exp(1); % Bootstrap sampling fraction: 1 - 1/e (63.2%)

figure
subplot(2,2,1)       % add first plot in 2 x 1 grid
idx = randsample(N,ceil(N*frac),1); % A new training set for each tree is generated by random sampling from dataset WITH replacement.
plot_toydata(data_train(idx,:));
title('Subplot 1')

subplot(2,2,2)       % add first plot in 2 x 1 grid
idx = randsample(N,ceil(N*frac),1); % A new training set for each tree is generated by random sampling from dataset WITH replacement.
plot_toydata(data_train(idx,:));
title('Subplot 2')

subplot(2,2,3)       % add first plot in 2 x 1 grid
idx = randsample(N,ceil(N*frac),1); % A new training set for each tree is generated by random sampling from dataset WITH replacement.
plot_toydata(data_train(idx,:));
title('Subplot 3')

subplot(2,2,4)       % add first plot in 2 x 1 grid
idx = randsample(N,ceil(N*frac),1); % A new training set for each tree is generated by random sampling from dataset WITH replacement.
plot_toydata(data_train(idx,:));
title('Subplot 4')

%%
% Set the random forest parameters for instance, 
param.num = 10;         % Number of trees
param.depth = 5;        % trees depth
param.splitNum = 3;     % Number of split functions to try
param.split = 'IG';     % Currently support 'information gain' only

%%%%%%%%%%%%%%%%%%%%%%
% Train Random Forest

% Grow all trees
trees = growTrees(data_train,param);

%%
%%%%%%%%%%%%%%%%%%%%%%
% Evaluate/Test Random Forest

% grab the few data points and evaluate them one by one by the leant RF
% test_point = [-.5 -.7; .4 .3; -.7 .4; .5 -.5];
% for n=1:4
%     leaves = testTrees([test_point(n,:) 0],trees);
%     % average the class distributions of leaf nodes of all trees
%     p_rf_sum = sum(trees(1).prob(leaves,:));
%     p_rf_mean = p_rf_sum/length(trees);
%     p_rf_mean
% end

% Test on the dense 2D grid data, and visualise the results ... 
predicted_labels = zeros(size(data_test,1), 1);
p_rf = zeros(size(data_test,1), 3);
for n=1:size(data_test, 1)
    leaves = testTrees([data_test(n,:) 0],trees);
    % average the class distributions of leaf nodes of all trees
    p_rf_sum = sum(trees(1).prob(leaves,:));
    p_rf_mean = p_rf_sum/length(trees);
    p_rf(n,:) = p_rf_mean;
    [~, predicted_labels(n,1)] = max(p_rf_mean);
    [data_test(n,3), predicted_labels(n,1)];
end
%%
figure;
% plot_toydata([data_test(:,1:end-1), predicted_labels]);
p_all = sum(p_rf,3);
imagesc([-1.5 1.5],[-1.5 1.5],reshape(p_all,151,151,3)/size(p_rf,3));
hold on;
plot_toydata(data_train(:,:));
% Change the RF parameter values and evaluate ... 


%%


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
% experiment with Caltech101 dataset for image categorisation
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

init;

% Select dataset
% we do bag-of-words technique to convert images to vectors (histogram of codewords)
% Set 'showImg' in getData.m to 0 to stop displaying training and testing images and their feature vectors
[data_train, data_test] = getData('Caltech');
close all;



% Set the random forest parameters ...
% Train Random Forest ...
% Evaluate/Test Random Forest ...
% show accuracy and confusion matrix ...


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
% random forest codebook for Caltech101 image categorisation
% .....



